{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f2b138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "import numpy as np \n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241203f3",
   "metadata": {},
   "source": [
    "## Improt dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0ba032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 58)\n",
      "tensor([[0.9815, 0.5792, 0.7743, 0.4597, 0.2425],\n",
      "        [0.5906, 0.0000, 0.0000, 0.7016, 0.0000],\n",
      "        [0.4127, 1.0959, 1.1392, 0.3097, 0.2467],\n",
      "        [0.3913, 0.0000, 0.0000, 0.8096, 0.0000],\n",
      "        [0.2632, 0.0000, 0.0000, 0.9049, 0.0000],\n",
      "        [0.4098, 1.0656, 1.1655, 0.2080, 0.4339],\n",
      "        [0.6278, 0.0000, 0.0000, 0.7014, 0.0000],\n",
      "        [0.5547, 0.4036, 0.8171, 0.4042, 0.1379],\n",
      "        [0.8957, 0.0000, 0.0000, 0.8092, 0.0000]]) tensor([[0.4460, 0.2124],\n",
      "        [0.4566, 0.0000],\n",
      "        [0.5768, 1.2455],\n",
      "        [0.9773, 0.0000],\n",
      "        [1.3776, 0.0000],\n",
      "        [0.3286, 0.1924],\n",
      "        [1.0394, 0.0000],\n",
      "        [0.5152, 0.2295],\n",
      "        [0.5267, 0.0000]])\n",
      "tensor([[0.9706, 0.5709, 0.7960, 0.4503, 0.2327],\n",
      "        [0.5032, 0.0000, 0.0000, 0.7044, 0.0000],\n",
      "        [0.4277, 1.0755, 1.1340, 0.3038, 0.2081],\n",
      "        [0.3046, 0.0000, 0.0000, 0.8077, 0.0000],\n",
      "        [0.2097, 0.0000, 0.0000, 0.9079, 0.0000],\n",
      "        [0.4823, 1.0276, 1.1585, 0.2019, 0.4060],\n",
      "        [0.6695, 0.0000, 0.0000, 0.7049, 0.0000],\n",
      "        [0.5317, 0.4680, 0.8224, 0.4045, 0.1249],\n",
      "        [0.8950, 0.0000, 0.0000, 0.8065, 0.0000]]) tensor([[0.4494, 0.2113],\n",
      "        [0.4599, 0.0000],\n",
      "        [0.5677, 0.8224],\n",
      "        [0.9436, 0.0000],\n",
      "        [1.3573, 0.0000],\n",
      "        [0.3226, 0.2458],\n",
      "        [1.0224, 0.0000],\n",
      "        [0.4779, 1.9221],\n",
      "        [0.5740, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"1.csv\",header=None)\n",
    "data=data.values\n",
    "#d = np.concatenate(([data[0]],data[1:3]),axis=0)\n",
    "#print(d)\n",
    "print(data.shape)\n",
    "node_feats = np.zeros((10000,9,5))\n",
    "label = np.zeros((10000,9,2))\n",
    "count = 0\n",
    "for row in data[0:10000]:\n",
    "    t1 = 0.1*row[0:9]\n",
    "    t2 = row[9:18]\n",
    "    l1 = row[18:27]\n",
    "    c1 = 0.001*row[27:36]\n",
    "    c2 = 0.01*row[36:45]\n",
    "    feas = np.array([t1, t2, l1, c1, c2]).T\n",
    "    flow = row[45:]\n",
    "    labels = np.array([[0.001*flow[0], 0.02*flow[1]],\n",
    "                       [0.001*flow[2], 0],\n",
    "                       [0.001*flow[3], 0.02*flow[4]],\n",
    "                       [0.001*flow[5], 0],\n",
    "                       [0.001*flow[6], 0],\n",
    "                       [0.001*flow[7], 0.02*flow[8]],\n",
    "                       [0.001*flow[9], 0],\n",
    "                       [0.001*flow[10],0.02*flow[11]],\n",
    "                       [0.001*flow[12],0]\n",
    "                      ])\n",
    "    node_feats[count] = feas\n",
    "    label[count] = labels\n",
    "    count = count + 1\n",
    "node_feats = torch.Tensor(node_feats)\n",
    "label = torch.Tensor(label)\n",
    "print(node_feats[0],label[0])\n",
    "print(node_feats[1],label[1])\n",
    "\n",
    "adj_matrix = torch.Tensor([\n",
    "    [0, 1, 1, 0, 1, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 1, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 1, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 1, 0, 0, 1, 1, 0, 1],\n",
    "    [1, 0, 1, 0, 0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 1, 1, 0, 0, 1],\n",
    "    [1, 0, 1, 0, 1, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 1, 0, 0, 1, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b01602",
   "metadata": {},
   "source": [
    "## Adaptive adjacency matrix and GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5a5661b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConv(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out, bias=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimensionality of input features\n",
    "            c_out - Dimensionality of output features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(c_in, c_out))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(c_out))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "        self.nodevec1 = nn.Parameter(torch.randn(9, 5), requires_grad=True)\n",
    "        self.nodevec2 = nn.Parameter(torch.randn(5, 9), requires_grad=True)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, node_feats, adj_matrix):\n",
    "        adj_matrix = F.softmax(F.relu(torch.mm(self.nodevec1, self.nodevec2)), dim=1)\n",
    "        support = torch.mm(node_feats, self.weight)\n",
    "        output = torch.spmm(adj_matrix, support)\n",
    "        deg = torch.diag(adj_matrix.sum(1))\n",
    "        out = torch.mm(torch.inverse(deg),output)\n",
    "        if self.bias is not None:\n",
    "            return out + self.bias, adj_matrix\n",
    "        else:\n",
    "            return out, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50e70c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat):\n",
    "        super(GraphAttentionLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "        \n",
    "        self.W = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.a = nn.Parameter(torch.Tensor(2*out_features, 1))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    \n",
    "    def forward(self, h, adj):\n",
    "        '''\n",
    "        h: (N, in_features)\n",
    "        adj: sparse matrix with shape (N, N)\n",
    "        '''\n",
    "        \n",
    "        Wh = torch.mm(h, self.W)  # (N, out_features)\n",
    "        Wh1 = torch.mm(Wh, self.a[:self.out_features, :])  # (N, 1)\n",
    "        Wh2 = torch.mm(Wh, self.a[self.out_features:, :])  # (N, 1)\n",
    "        \n",
    "        e = self.leakyrelu(Wh1 + Wh2.T)                    # (N, N)\n",
    "        padding = (-2 ** 31) * torch.ones_like(e)          # (N, N)\n",
    "        attention = torch.where(adj > 0, e, padding)       # (N, N)\n",
    "        attention = F.softmax(attention, dim=1)            # (N, N)\n",
    "\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        \n",
    "        h_prime = torch.matmul(attention, Wh)              # (N, out_features)\n",
    "        if self.concat:\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            return h_prime\n",
    "\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.MH = nn.ModuleList([\n",
    "            GraphAttentionLayer(nfeat, nhid, dropout, alpha, concat=True)\n",
    "            for _ in range(nheads)\n",
    "        ])\n",
    "        self.out_att = GraphAttentionLayer(nhid*nheads, nclass, dropout, alpha, concat=False)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        x = F.dropout(x, self.dropout, training=self.training)    # (N, nfeat)\n",
    "        x = torch.cat([head(x, adj) for head in self.MH], dim=1)  # (N, nheads*nhid)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)    # (N, nheads*nhid)\n",
    "        x = F.elu(self.out_att(x, adj))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c90385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, nlayer):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            nfeat - Dimensionality of input features\n",
    "            nhid - Dimensionality of hidden feature representation\n",
    "            nclass - Number of classes\n",
    "            nlayer - Number of layers\n",
    "        \"\"\"\n",
    "\n",
    "        super(GCN, self).__init__()\n",
    "        \n",
    "        # A list of graph convolution layers\n",
    "        self.convs = torch.nn.ModuleList([GraphConv(nfeat,nhid)]+[GraphConv(nhid,nhid) for i in range(nlayer-2)]+[GraphConv(nhid,nclass)])\n",
    "\n",
    "        # The log softmax layer\n",
    "        self.softmax = torch.nn.LogSoftmax()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # TODO: Implement a function that takes the node features x and\n",
    "        # adjacency matrix adj and returns the predicted labels.\n",
    "\n",
    "        out = None\n",
    "        out = x\n",
    "        n = len(self.convs)\n",
    "        adj_list = []\n",
    "        for layer in self.convs:\n",
    "            n = n-1\n",
    "            out,adj = layer(out,adj)\n",
    "            adj_list.append(adj)\n",
    "            if n > 0:\n",
    "                out = torch.nn.functional.relu(out,0.001)\n",
    "        return out,adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be38cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        'device': torch.cuda.is_available(),\n",
    "        'num_layers': 2, #GCN 2\n",
    "        'hidden_dim': 32,\n",
    "        'lr': 0.0001, #0.00005\n",
    "        'weight_decay': 5e-4,\n",
    "        'epochs': 200,\n",
    "        'fastmode': False\n",
    "    }\n",
    "\n",
    "model = GCN(nfeat=node_feats.shape[2],\n",
    "            nhid=args['hidden_dim'],\n",
    "            nclass=2,\n",
    "            nlayer=args['num_layers'])\n",
    "\n",
    "#model = nfeat, nhid, nclass, dropout, alpha, nheads\n",
    "#model = GAT(nfeat=node_feats.shape[2],\n",
    "#            nhid=args['hidden_dim'],\n",
    "#            nclass=2,\n",
    "#            dropout = 0,\n",
    "#            alpha = 0.2,\n",
    "#            nheads = 5) #2\n",
    "\n",
    "# optimizers\n",
    "#optimizer = optim.Adam(model.parameters(),\n",
    "#                       lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "#optimizer = optim.RMSprop(model.parameters(),\n",
    "#                       lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                       lr=args['lr'], weight_decay=args['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c973d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args['device']:\n",
    "    model.cuda()\n",
    "    node_feats = node_feats.cuda()\n",
    "    adj_matrxi = adj_matrix.cuda()\n",
    "    label = label.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e82f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch,ep_features,ep_labels):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    loss_function=torch.nn.MSELoss()\n",
    "    optimizer.zero_grad()\n",
    "    output,adj = model(ep_features[0],adj_matrix)\n",
    "    output = output.unsqueeze(0)\n",
    "    for i in range(1,16):\n",
    "        output_,adj = model(ep_features[i],adj_matrix)\n",
    "        output = torch.cat((output, output_.unsqueeze(0)), 0)\n",
    "    #loss_train = torch.nn.functional.nll_loss(output[idx_train], labels[idx_train])\n",
    "    #print(output, label)\n",
    "    loss_train = loss_function(output, ep_labels)\n",
    "\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "    #      'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "    #      'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "    #      'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "    return output,loss_train\n",
    "\n",
    "def test():\n",
    "    t_test = time.time()\n",
    "    model.eval()\n",
    "    loss_function=torch.nn.MSELoss()\n",
    "    loss_mae = torch.nn.L1Loss()\n",
    "    test_feats = node_feats[8000:9000]\n",
    "    \n",
    "    output,adj = model(test_feats[0],adj_matrix)\n",
    "    print(output, label[8000])\n",
    "    output = output.unsqueeze(0)\n",
    "    for i in range(1,1000):\n",
    "        output_,adj = model(test_feats[i],adj_matrix)\n",
    "        output = torch.cat((output, output_.unsqueeze(0)), 0)\n",
    "\n",
    "    #MSE\n",
    "    MSEloss = loss_function(output, label[8000:9000])\n",
    "    #MAE\n",
    "    MAEloss =  loss_mae(output, label[8000:9000])\n",
    "    #MAPE\n",
    "    output = output.detach().numpy()\n",
    "    label_cal_loss = label[8000:9000].numpy()\n",
    "    MAPEloss = np.fabs((label_cal_loss-output)/np.clip(label_cal_loss,0.2,2)).mean()\n",
    " \n",
    "\n",
    "    print(MSEloss, MAEloss, MAPEloss)\n",
    "    print(\"Test set results:\",\n",
    "         'time: {:.4f}s'.format(time.time() - t_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfcc5e1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.4623 time: 0.0118s\n",
      "Epoch: 0001 loss_train: 1.4531 time: 0.0098s\n",
      "Epoch: 0001 loss_train: 1.4665 time: 0.0064s\n",
      "Epoch: 0001 loss_train: 1.4689 time: 0.0063s\n",
      "Epoch: 0001 loss_train: 1.4636 time: 0.0059s\n",
      "Epoch: 0001 loss_train: 1.4467 time: 0.0054s\n",
      "Epoch: 0001 loss_train: 1.4423 time: 0.0054s\n",
      "Epoch: 0001 loss_train: 1.4626 time: 0.0062s\n",
      "Epoch: 0001 loss_train: 1.4415 time: 0.0049s\n",
      "Epoch: 0001 loss_train: 1.4735 time: 0.0047s\n",
      "Epoch: 0001 loss_train: 1.4570 time: 0.0043s\n",
      "Epoch: 0001 loss_train: 1.4362 time: 0.0040s\n",
      "Epoch: 0001 loss_train: 1.4551 time: 0.0037s\n",
      "Epoch: 0001 loss_train: 1.4349 time: 0.0038s\n",
      "Epoch: 0001 loss_train: 1.4492 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.4309 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.4809 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4313 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4300 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4644 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4461 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4629 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.4269 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4405 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4602 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.4228 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4553 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.4241 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4357 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4176 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.4393 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.4135 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.4146 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.4197 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4069 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4261 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4079 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4067 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4226 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4197 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4050 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4003 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4272 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3998 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4038 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3948 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4313 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3961 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4102 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3905 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4072 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4198 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4073 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.4001 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3861 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3845 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4012 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.4150 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.3823 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.3817 time: 0.0039s\n",
      "Epoch: 0001 loss_train: 1.3795 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.3756 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3945 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3765 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3923 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.3735 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3744 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3947 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3870 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3709 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3690 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3674 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3830 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3711 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3648 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3594 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.4187 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3598 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3781 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3784 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3560 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3557 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3729 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3676 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3708 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3663 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3639 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.4011 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3435 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3841 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3650 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3614 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3583 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3401 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3423 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3419 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3399 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3552 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3366 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3339 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3680 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3342 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3331 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3363 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3457 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3305 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3444 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3278 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3430 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3492 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3522 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3229 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3213 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3185 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.3358 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.3173 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.3209 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3144 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3153 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.3141 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.3119 time: 0.0037s\n",
      "Epoch: 0001 loss_train: 1.3097 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.3121 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3118 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3072 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.3066 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.3258 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3239 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3045 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3216 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3069 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2992 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3007 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3013 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.3134 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3129 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2981 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2967 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2980 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2909 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2891 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2926 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2922 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2902 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2911 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2879 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2843 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2854 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3009 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2998 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2815 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2948 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2793 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3012 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3014 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.3115 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2727 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2916 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2893 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2683 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2765 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2683 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2884 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2675 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2934 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2664 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2657 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2953 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2619 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2643 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2604 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2576 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2924 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2744 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2727 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2556 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2502 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.2715 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2517 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2534 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2520 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.2495 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.2490 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.2483 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2469 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2447 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2450 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2606 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2524 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2604 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2371 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.2564 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2598 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2357 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2721 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2372 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.2330 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.2336 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2487 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2319 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2472 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2287 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2320 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2518 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2251 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2385 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.2248 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2373 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2242 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2432 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2201 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2216 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2177 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2179 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2175 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2157 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2156 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2207 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2129 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2105 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2379 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2103 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2512 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2097 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2395 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2243 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2070 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2209 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2044 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2004 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2015 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1994 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1990 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1971 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2041 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2115 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1948 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1974 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 1.2083 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.1923 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2068 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1951 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1943 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.1874 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2048 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.1947 time: 0.0035s\n",
      "Epoch: 0001 loss_train: 1.2038 time: 0.0034s\n",
      "Epoch: 0001 loss_train: 1.2172 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.2032 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1886 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1813 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.2162 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1803 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1824 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1937 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.1765 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.1762 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1746 time: 0.0033s\n",
      "Epoch: 0001 loss_train: 1.1872 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1735 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1721 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1736 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1844 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1672 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1702 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1674 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1677 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1756 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1635 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1775 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1648 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1785 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1757 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1743 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1646 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1764 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1584 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1597 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1582 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1550 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1598 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1548 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1697 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1512 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1665 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1487 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1670 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1674 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1473 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1451 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1448 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1626 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1444 time: 0.0031s\n",
      "Epoch: 0001 loss_train: 1.1432 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1447 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1687 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1394 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1377 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1581 time: 0.0032s\n",
      "Epoch: 0001 loss_train: 1.1526 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1464 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.1372 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1503 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1541 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1482 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 1.1327 time: 0.0037s\n",
      "Epoch: 0002 loss_train: 1.1284 time: 0.0038s\n",
      "Epoch: 0002 loss_train: 1.1486 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1287 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.1601 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1447 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1247 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.1439 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1239 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.1379 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1207 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 1.1694 time: 0.0037s\n",
      "Epoch: 0002 loss_train: 1.1221 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.1218 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1542 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1375 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1535 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1195 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1326 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.1522 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1165 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1480 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1182 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1295 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1129 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1341 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1099 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.1106 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1155 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1044 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1228 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1050 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1047 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1204 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1170 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1040 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1002 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1256 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1002 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1037 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0956 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1311 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0974 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.1113 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0928 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1094 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1216 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1095 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1029 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0901 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0881 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1050 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1185 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0870 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0870 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0854 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0817 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0999 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0829 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0984 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0806 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0818 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.1019 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 1.0946 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0788 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0778 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0763 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0918 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0807 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0748 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0702 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1268 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0706 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0886 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0895 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0679 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0680 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0855 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0799 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0832 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0792 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0776 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.1136 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0583 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0976 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0793 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0762 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0739 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0560 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0585 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0583 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0560 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0719 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0538 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0519 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0847 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0520 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0516 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0552 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0643 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0498 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0640 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0477 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0624 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0693 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0723 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0441 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0426 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0400 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0572 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0395 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0433 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0377 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0387 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0374 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0360 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0340 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0002 loss_train: 1.0368 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 1.0365 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0323 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0320 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0504 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0493 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0308 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 1.0476 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0338 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0267 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0276 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0283 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0406 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0410 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0262 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0252 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0272 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0206 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0192 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0221 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0223 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0206 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0214 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0191 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0162 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 1.0171 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0320 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 1.0315 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0139 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0274 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0121 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0339 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0341 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0444 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0071 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0256 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0236 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0031 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0115 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0040 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0237 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0033 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0288 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0033 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0026 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 1.0322 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9997 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0024 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9988 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9963 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0304 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0135 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0113 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9954 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9907 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0114 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9926 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9940 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9932 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9916 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9904 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 0.9904 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9897 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9873 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9880 time: 0.0037s\n",
      "Epoch: 0002 loss_train: 1.0031 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9954 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 1.0033 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9810 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0003 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 1.0035 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9805 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0163 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9828 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 0.9788 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9796 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9941 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9783 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9937 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9756 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9796 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9989 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9729 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9865 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9729 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9859 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9732 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9920 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9694 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9716 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9684 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9687 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9687 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9666 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 0.9667 time: 0.0037s\n",
      "Epoch: 0002 loss_train: 0.9724 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9648 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9629 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9896 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9630 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 1.0026 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9627 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9919 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9776 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9610 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9745 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9590 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9555 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9570 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9553 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9552 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9535 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9605 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9678 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9517 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9546 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9654 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9506 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9642 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9529 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9527 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9465 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9632 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9543 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 0.9630 time: 0.0036s\n",
      "Epoch: 0002 loss_train: 0.9758 time: 0.0039s\n",
      "Epoch: 0002 loss_train: 0.9626 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9491 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9423 time: 0.0035s\n",
      "Epoch: 0002 loss_train: 0.9765 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9416 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9439 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9555 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9389 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9387 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9374 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9500 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9366 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9359 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9371 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9481 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9319 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9346 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9321 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9326 time: 0.0034s\n",
      "Epoch: 0002 loss_train: 0.9408 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9294 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9426 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9308 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9446 time: 0.0033s\n",
      "Epoch: 0002 loss_train: 0.9422 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9408 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9317 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9432 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9261 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9277 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9264 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9241 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9287 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9240 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9385 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9211 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9361 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9188 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9367 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9376 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9178 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9161 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9160 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9336 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9162 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9152 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9169 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9401 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9122 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9112 time: 0.0031s\n",
      "Epoch: 0002 loss_train: 0.9314 time: 0.0032s\n",
      "Epoch: 0002 loss_train: 0.9256 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.9202 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9114 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9239 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9285 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.9223 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.9078 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.9037 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.9235 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.9045 time: 0.0039s\n",
      "Epoch: 0003 loss_train: 0.9354 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.9205 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.9016 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9206 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9010 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.9146 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8984 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.9456 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9002 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.9003 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9313 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9157 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.9312 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8986 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.9115 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9308 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8963 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9272 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8984 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.9096 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8938 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9143 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8913 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8919 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8970 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8869 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.9046 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8873 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8875 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9031 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8996 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8875 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8840 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9083 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8845 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8874 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8803 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.9151 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8826 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8961 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8785 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8948 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.9069 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8950 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8888 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8770 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8749 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8914 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.9052 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8743 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8747 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8736 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8700 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8877 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8714 time: 0.0031s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 loss_train: 0.8868 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.8696 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8709 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8909 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8841 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8685 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8679 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8668 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.8821 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.8715 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8660 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8620 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.9163 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.8625 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8801 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8813 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8605 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8608 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.8783 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8730 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8760 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.8726 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8714 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.9065 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8530 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8912 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8734 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8706 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8691 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8514 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8542 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8541 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8519 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8681 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8505 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8491 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8808 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8491 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8492 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8528 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8619 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8482 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8620 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8465 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8607 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8680 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8712 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8438 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8425 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8400 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8570 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8399 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8438 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8388 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8399 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8388 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8378 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8358 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8385 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8386 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8347 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8346 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.8525 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8519 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8342 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8506 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8375 time: 0.0036s\n",
      "Epoch: 0003 loss_train: 0.8309 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8316 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8326 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8447 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.8456 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8312 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8305 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8325 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8264 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8254 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8279 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8287 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8271 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8282 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8262 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8238 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8246 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8389 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8387 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8219 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8354 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8205 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8420 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8423 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8529 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8168 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8348 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8330 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8131 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8212 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8143 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8336 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8137 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8392 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8145 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8138 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8433 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8117 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8142 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8111 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8089 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8421 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8259 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8235 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8085 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8042 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8245 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8065 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8078 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8075 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8061 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8050 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8052 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8048 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8027 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8035 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.8185 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.8106 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8187 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7973 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8164 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8196 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7973 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.8322 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7999 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7960 time: 0.0034s\n",
      "Epoch: 0003 loss_train: 0.7972 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8116 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.7962 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.8116 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7939 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7981 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8171 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7918 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8054 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7922 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8054 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7931 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8114 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7894 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7919 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7890 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7895 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7895 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7874 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7877 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7936 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7865 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7849 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8112 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7853 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8240 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7852 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8142 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8002 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7841 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7974 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7825 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7794 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7808 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7796 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7797 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7780 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7852 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7926 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7769 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7798 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7905 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7764 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7897 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7787 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7788 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7733 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7895 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7811 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7898 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8026 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7893 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 loss_train: 0.7764 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.7704 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.8037 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7699 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7723 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7842 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7679 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7678 time: 0.0035s\n",
      "Epoch: 0003 loss_train: 0.7668 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7793 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7665 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7659 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7672 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7783 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7625 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7652 time: 0.0033s\n",
      "Epoch: 0003 loss_train: 0.7632 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7639 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7719 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7612 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7741 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7627 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7767 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7744 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7735 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7647 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7758 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7593 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7610 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7602 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7582 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7628 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7583 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7729 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7562 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7710 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7540 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7717 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7729 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7539 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7522 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7525 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7699 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7530 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7525 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7541 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7772 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7503 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7493 time: 0.0032s\n",
      "Epoch: 0003 loss_train: 0.7692 time: 0.0031s\n",
      "Epoch: 0003 loss_train: 0.7636 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7589 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7506 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7626 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7676 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7618 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7476 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7439 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7634 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7451 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7757 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7611 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7429 time: 0.0035s\n",
      "Epoch: 0004 loss_train: 0.7617 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7428 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7563 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7407 time: 0.0035s\n",
      "Epoch: 0004 loss_train: 0.7868 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.7430 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7429 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7736 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7585 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7743 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7419 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7552 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7740 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7405 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7709 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7428 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7542 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7391 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7592 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7368 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7378 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7430 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7335 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7509 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7342 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7345 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7500 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7469 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7351 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7320 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7556 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7325 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7357 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7294 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7636 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7319 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7455 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7285 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7444 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7566 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7446 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7392 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7276 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7258 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7422 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7560 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7259 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7262 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7259 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7224 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7398 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7238 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7393 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7225 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7241 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7436 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7373 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7222 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7217 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7211 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7365 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7257 time: 0.0035s\n",
      "Epoch: 0004 loss_train: 0.7208 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7173 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7705 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7183 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.7354 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.7369 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.7165 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7175 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7347 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7294 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7327 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7295 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7284 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7630 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7110 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7484 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7309 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7288 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7276 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7101 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7133 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7129 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7112 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7276 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7105 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7092 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7408 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7096 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7100 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7131 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7226 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7090 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7232 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7081 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7223 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7295 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7332 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7064 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7052 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7029 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7202 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7034 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7072 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7026 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7040 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7028 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7025 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7009 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7033 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7036 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7002 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7000 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7178 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7176 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7002 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7169 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7037 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6981 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6989 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6999 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7122 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0004 loss_train: 0.7130 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.6988 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6986 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7008 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6952 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6944 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6969 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6980 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.6967 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6979 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6962 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6936 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6948 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7098 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7089 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6930 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7065 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6919 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7131 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7139 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7241 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6895 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7072 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7055 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6862 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6937 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6878 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7068 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6878 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7127 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6883 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6881 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7172 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6865 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6888 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6864 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6844 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7173 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7015 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6992 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6850 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6809 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7008 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6834 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6846 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6845 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6836 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6822 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6830 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6827 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6810 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6819 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6969 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6893 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6978 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6768 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6954 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6989 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6770 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.7116 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6801 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6765 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6781 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.6922 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6774 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6929 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6752 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6799 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.6986 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6737 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6877 time: 0.0034s\n",
      "Epoch: 0004 loss_train: 0.6747 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6879 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6759 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6938 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6725 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6746 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6726 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6736 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6729 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6715 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6720 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6778 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6715 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6699 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6961 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6705 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.7091 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6712 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6996 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6861 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6700 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6835 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6693 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6665 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6680 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6668 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6670 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6658 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6728 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6802 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6648 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6680 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6783 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6650 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6783 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6676 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6675 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6627 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6789 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6708 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6793 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6924 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6790 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6665 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6611 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6939 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6607 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6635 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6751 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6592 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6591 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6586 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6707 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6583 time: 0.0035s\n",
      "Epoch: 0004 loss_train: 0.6577 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6593 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6705 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6550 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6578 time: 0.0035s\n",
      "Epoch: 0004 loss_train: 0.6562 time: 0.0033s\n",
      "Epoch: 0004 loss_train: 0.6569 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6648 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6544 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6671 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6562 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6704 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6680 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6674 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6589 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6698 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6532 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6552 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6549 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6530 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6578 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6532 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6676 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6516 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6663 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6495 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6670 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6684 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6499 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6485 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6484 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6660 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6494 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6491 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6506 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6738 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6471 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6465 time: 0.0031s\n",
      "Epoch: 0004 loss_train: 0.6659 time: 0.0032s\n",
      "Epoch: 0004 loss_train: 0.6609 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6562 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6480 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6602 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6652 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6595 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6456 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6418 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6617 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6438 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6740 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6595 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6418 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6606 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6418 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6552 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6401 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6857 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6424 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6426 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6729 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6579 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 loss_train: 0.6739 time: 0.0034s\n",
      "Epoch: 0005 loss_train: 0.6418 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6551 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6739 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6408 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6707 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6433 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6546 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6400 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6596 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6381 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6386 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6441 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6351 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6523 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6359 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6361 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6520 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6488 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6371 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6343 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6572 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6346 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6379 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6323 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6659 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6347 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6485 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6317 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6476 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6596 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6478 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6425 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6312 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6296 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6460 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6596 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6300 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6302 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6304 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6267 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6441 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6282 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6440 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6275 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6288 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6483 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6424 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6278 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6268 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6265 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6420 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6311 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6267 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6233 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6759 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6247 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6416 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6431 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6230 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6242 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6418 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6357 time: 0.0035s\n",
      "Epoch: 0005 loss_train: 0.6395 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6366 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6354 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6700 time: 0.0035s\n",
      "Epoch: 0005 loss_train: 0.6187 time: 0.0034s\n",
      "Epoch: 0005 loss_train: 0.6556 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6381 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6367 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6357 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6180 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6215 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6209 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6195 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6359 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6192 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6179 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6491 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6181 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6190 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6215 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6315 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6178 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6325 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6174 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6312 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6385 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6426 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6159 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6148 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6125 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6299 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6135 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6170 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6126 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6141 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6128 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6130 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6113 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6139 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6139 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6111 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6109 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6281 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6282 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6111 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6279 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6147 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6096 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6099 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6110 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6233 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6241 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6098 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6101 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6125 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6071 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6065 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6086 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6098 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6090 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6099 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6085 time: 0.0034s\n",
      "Epoch: 0005 loss_train: 0.6059 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6072 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6222 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6207 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6054 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6188 time: 0.0034s\n",
      "Epoch: 0005 loss_train: 0.6042 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6257 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6263 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6365 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6027 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6200 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6184 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5993 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6069 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6012 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6198 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6011 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6260 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6019 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6015 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6307 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6004 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6024 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6003 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5983 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6312 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6157 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6130 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5993 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5953 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6151 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5981 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5989 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5990 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5984 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5967 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5978 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5976 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5961 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5969 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6118 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6041 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6128 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5922 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6105 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6140 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5924 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6265 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5956 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5921 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5938 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6079 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5932 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6087 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5911 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5961 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6147 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5895 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6038 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5910 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 loss_train: 0.6045 time: 0.0034s\n",
      "Epoch: 0005 loss_train: 0.5926 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6098 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5889 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5909 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.5894 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.5906 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.5896 time: 0.0034s\n",
      "Epoch: 0005 loss_train: 0.5882 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5888 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5948 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5885 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5871 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.6134 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5878 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6262 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5890 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6168 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.6037 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5875 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6010 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5870 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5845 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5862 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5848 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5851 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5842 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5910 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5982 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5831 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5863 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5965 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5838 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5967 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5861 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5863 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5816 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5972 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5898 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5981 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6113 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5977 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5857 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5804 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.6130 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5801 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5832 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5946 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5789 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5787 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5785 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5904 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5784 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5777 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5792 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5904 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5754 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5781 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5767 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5771 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5851 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5747 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5875 time: 0.0035s\n",
      "Epoch: 0005 loss_train: 0.5770 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5912 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5884 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5883 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5798 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5904 time: 0.0035s\n",
      "Epoch: 0005 loss_train: 0.5741 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5761 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5761 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5744 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5791 time: 0.0033s\n",
      "Epoch: 0005 loss_train: 0.5747 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5886 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5729 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5877 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5710 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5883 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5898 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5716 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5704 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5701 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5878 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5713 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5711 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5726 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5957 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5693 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5689 time: 0.0031s\n",
      "Epoch: 0005 loss_train: 0.5881 time: 0.0032s\n",
      "Epoch: 0005 loss_train: 0.5833 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5785 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5707 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5826 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5878 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5821 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5684 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5647 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5847 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5670 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5968 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5826 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5651 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5840 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5650 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5783 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5634 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.6087 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5657 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5662 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5962 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5812 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5975 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5654 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5789 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5974 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5649 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5942 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5674 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5786 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5644 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5835 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5627 time: 0.0035s\n",
      "Epoch: 0006 loss_train: 0.5629 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5683 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5599 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5768 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5605 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5608 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5767 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5735 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5620 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5593 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5816 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5596 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5629 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5576 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5907 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5600 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5740 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5574 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5729 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5849 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5733 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5679 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5569 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5555 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5716 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5853 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5559 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5561 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5565 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5527 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5699 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5542 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5701 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5540 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5551 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5742 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5687 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5543 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5532 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5531 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5683 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5575 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5536 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5501 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.6021 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5516 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5684 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5698 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5501 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5512 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5689 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5625 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5667 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5637 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5625 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5968 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5463 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5827 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5653 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5641 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5633 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5458 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0006 loss_train: 0.5492 time: 0.0034s\n",
      "Epoch: 0006 loss_train: 0.5486 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5474 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5637 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5472 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5460 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5768 time: 0.0034s\n",
      "Epoch: 0006 loss_train: 0.5462 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5473 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5496 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5597 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5461 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5609 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5457 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5594 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5667 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5708 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5445 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5436 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5411 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5584 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5424 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5457 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5414 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5431 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5419 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5421 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5406 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5431 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5430 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5404 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5403 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5572 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5574 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5406 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5574 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5441 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5393 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5396 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5406 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5528 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5537 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5396 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5400 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5425 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5372 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5366 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5387 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5400 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5393 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5402 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5388 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5363 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5377 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5524 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5510 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5360 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5493 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5348 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5559 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5567 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5669 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5337 time: 0.0035s\n",
      "Epoch: 0006 loss_train: 0.5506 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5491 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5303 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5377 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5323 time: 0.0036s\n",
      "Epoch: 0006 loss_train: 0.5507 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5322 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5568 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5331 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5328 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5618 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5318 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5335 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5318 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5297 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5624 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5471 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5443 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5310 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5272 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5466 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5299 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5307 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5309 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5304 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5286 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5298 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5298 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5284 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5290 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5439 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5362 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5449 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5247 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5426 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5462 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5249 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5584 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5282 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5247 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5264 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5403 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5260 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5414 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5239 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5288 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5473 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5223 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5366 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5240 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5374 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5256 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5426 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5221 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5240 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5228 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5238 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5228 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5215 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5220 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5280 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5220 time: 0.0034s\n",
      "Epoch: 0006 loss_train: 0.5207 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5465 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5213 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5592 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5225 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5500 time: 0.0036s\n",
      "Epoch: 0006 loss_train: 0.5372 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5212 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5346 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5207 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5184 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5202 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5186 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5191 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5183 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5250 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5321 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5173 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5204 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5305 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5180 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5308 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5202 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5206 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5161 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5313 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5242 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5324 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5455 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5319 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5202 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5150 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5473 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5148 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5180 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5292 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5138 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5136 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5134 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5252 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5133 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5127 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5142 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5253 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5106 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5131 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5118 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5123 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5201 time: 0.0034s\n",
      "Epoch: 0006 loss_train: 0.5099 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5226 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5123 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5264 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5236 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5235 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5152 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5256 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5096 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5116 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5116 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5102 time: 0.0032s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0006 loss_train: 0.5147 time: 0.0034s\n",
      "Epoch: 0006 loss_train: 0.5104 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5240 time: 0.0031s\n",
      "Epoch: 0006 loss_train: 0.5088 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5232 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5068 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5239 time: 0.0034s\n",
      "Epoch: 0006 loss_train: 0.5256 time: 0.0036s\n",
      "Epoch: 0006 loss_train: 0.5076 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5064 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5060 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5236 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5074 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5071 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5086 time: 0.0033s\n",
      "Epoch: 0006 loss_train: 0.5313 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5054 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5052 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5240 time: 0.0032s\n",
      "Epoch: 0006 loss_train: 0.5194 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5147 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5070 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5188 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5240 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5184 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5048 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5013 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5211 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5036 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5330 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5191 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5019 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5206 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5018 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5149 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5003 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5449 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5026 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5031 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5326 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5180 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5341 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5024 time: 0.0032s\n",
      "Epoch: 0007 loss_train: 0.5157 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5340 time: 0.0031s\n",
      "Epoch: 0007 loss_train: 0.5020 time: 0.0036s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m inner_loss_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#output, loss_ = train(epoch, node_feats[epoch%6000],label[epoch%6000])\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     output, loss_ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     inner_loss_list\u001b[38;5;241m.\u001b[39mappend(loss_\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     11\u001b[0m loss_ep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(inner_loss_list)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(inner_loss_list)\n",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch, ep_features, ep_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     output_,adj \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mep_features\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((output, output_\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#loss_train = torch.nn.functional.nll_loss(output[idx_train], labels[idx_train])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(output, label)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1363\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1362\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs:\n\u001b[1;32m     32\u001b[0m     n \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 33\u001b[0m     out,adj \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     adj_list\u001b[38;5;241m.\u001b[39mappend(adj)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1363\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1362\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1364\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1365\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, node_feats, adj_matrix)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_feats, adj_matrix):\n\u001b[0;32m---> 27\u001b[0m     adj_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodevec1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodevec2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     support \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(node_feats, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m     29\u001b[0m     output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mspmm(adj_matrix, support)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:1841\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1841\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t_total = time.time()\n",
    "best_model = None\n",
    "best_valid_acc = 0\n",
    "loss_list = []\n",
    "for epoch in range(args['epochs']):\n",
    "    inner_loss_list = []\n",
    "    for batch in range(300):\n",
    "    #output, loss_ = train(epoch, node_feats[epoch%6000],label[epoch%6000])\n",
    "        output, loss_ = train(epoch, node_feats[batch*16:(batch+1)*16],label[batch*16:(batch+1)*16])\n",
    "        inner_loss_list.append(loss_.detach().float())\n",
    "    loss_ep = sum(inner_loss_list)/len(inner_loss_list)\n",
    "    loss_list.append(loss_ep)\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa6dd6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(1.2945472, dtype=float32), array(1.0258076, dtype=float32), array(0.83270615, dtype=float32), array(0.7026798, dtype=float32), array(0.6141661, dtype=float32), array(0.5442072, dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "loss_list_ = []\n",
    "for i in loss_list:\n",
    "    loss_list_.append(i.detach().numpy())\n",
    "import matplotlib.pyplot as plt\n",
    "fig1 = plt.figure(figsize=(10,8))\n",
    "#fig1.subplots_adjust(bottom = 0,wspace = 1)\n",
    "ax1 = fig1.add_subplot(111)\n",
    "ax1.plot(loss_list_, color='#36ACA2', linewidth=1.6)\n",
    "ax1.set_ylabel('Loss', fontsize=16)\n",
    "ax1.set_xlabel('Epoch',fontsize=16)\n",
    "ax1.grid()\n",
    "#plt.show()\n",
    "plt.show()\n",
    "print(loss_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124c2d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
